---
title: "Bioinformatics Project Template"
author: "David Martín-Gálvez"
date: today
format:
  html: 
    theme: default
    toc: true
    number-sections: true
    embed-resources: true
editor: source
execute: 
  eval: false
  echo: true
---

# Purpose

A generalized template to structure bioinformatics analysis projects (RNA-seq, ChIP-seq, metagenomics, variant calling, proteomics, etc.). It covers:
- Standard folder layout
- Minimal software requirements
- Initialization scripts
- Git + SSH key setup and basic cluster access

# Minimal Software

- Shell & CLI:
  - bash ≥ 4.0, coreutils, `awk`, `sed`, `grep`, `rsync`, `tar`, `gzip`
- YAML:
  - `yq` (mikefarah/yq) to read YAML with bash
- Documentation:
  - Quarto (optional but recommended): https://quarto.org
- VCS:
  - Git ≥ 2.30
- Optional (depending on analysis):

  <!-- - Conda/Mamba for reproducible environments
  - Snakemake or Nextflow for workflows
  - R (≥4.2) and/or Python (≥3.10) -->

Quick install (macOS):

First, install Homebrew if you don't have it (https://brew.sh):

```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

Then install the required packages:

```bash
brew install yq git quarto rsync gnu-sed gawk
```

# Git Setup

Initialize and connect to remote:

```bash
git init
# create the remote on GitHub/GitLab, then:
git remote add origin https://github.com/<user>/<repo>.git
git config user.name "Your Name"
git config user.email "you@email"
git add .
git commit -m "Initial template"
git push -u origin main
```

Ignore local files:

```
config/config_local.yaml
analyses/
data/processed/
logs/
```

# SSH Keys (Git + Cluster)

## Generate keys

```bash
ssh-keygen -t ed25519 -C "you@email" -f ~/.ssh/id_ed25519
# start agent
ssh-agent -s
ssh-add ~/.ssh/id_ed25519
cat ~/.ssh/id_ed25519.pub
```

Copy the public key to:
- GitHub/GitLab (SSH keys)
- Cluster (`~/.ssh/authorized_keys` on your user account)

## Connect to the cluster

```bash
ssh user@cluster.univ.es
# optional: add an alias
cat >> ~/.ssh/config <<'CFG'
Host cluster
  HostName cluster.univ.es
  User user
  IdentityFile ~/.ssh/id_ed25519
CFG
ssh cluster
```

# Folder Structure

```
project-root/
  README.md
  config/
    config.yaml            # project-level paths and parameters
    config_local.yaml      # machine/cluster-specific absolute paths
  docs/
    bioinformatics_project_template.qmd  # this guide
  scripts/
    setup/
      init_project.sh      # scaffolds folders and templates
    utils/
      load_config.sh       # load YAML into environment variables
    templates/
      job_slurm_template.sh
      analysis_script_template.sh
  analyses/                # results and reports
  data/
    raw/                   # original data (read-only)
    processed/             # processed data
  reference/               # genomes, annotations, indices
  logs/                    # job logs (e.g., SLURM)
```

Notes:
- `config_local.yaml` may be untracked if it contains private paths — add to `.gitignore`.
- Treat `data/raw` as immutable; never write into it.




# Configure `config.yaml` and `config_local.yaml`

Generic `config.yaml` example:

```yaml
paths:
  data_raw: data/raw
  data_processed: data/processed
  reference: reference
  analyses: analyses
project:
  name: "my-analysis"
cluster:
  threads: 8
  memory: "16G"
  queue: "short"
```

Local `config_local.yaml` example:

```yaml
base_dir: "~/Projects/my-analysis"
repo_dir: "~/Projects/my-analysis/repo"
```

# Initialize the Project

Use `scripts/setup/init_project.sh` to create folders and templates:

```bash
bash scripts/setup/init_project.sh
```

This script will:
- Create base folders (`data/raw`, `data/processed`, `reference`, `analyses`, `logs`)
- Copy script templates (`scripts/templates`)
- Create `config/config.yaml` and `config/config_local.yaml` if missing

# Best Practices

- Always `source scripts/utils/load_config.sh` at the start of analysis scripts.
- Never modify `data/raw`; write outputs to `data/processed` or `analyses`.
- Track only code and generic config; keep large data out of the repo (or use Git LFS).
- Document in `docs/` and publish reports with Quarto.

# Next Steps

- Add workflows (Snakemake/Nextflow) tailored to your analysis.
- Create reproducible environments (`environment.yml`, `renv.lock`, or `requirements.txt`).
